{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1dQrrPqr1qwC3cno_z4q9mZl4DDJrfIhF",
      "authorship_tag": "ABX9TyPUv+PhYkiyH2uBegW7eSsU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ersel26/echo_KVAK/blob/main/echo_KVAK_efficientNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W1TD-QRx6kU5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "data_dict = {}\n",
        "\n",
        "CATEGORIES = ['A2C', 'A3C', 'A4C', 'A5C', 'PLAX', 'PSAX', 'Others']\n",
        "DIRECTORY = r\"/content/drive/MyDrive/Echo_KVAK/labeled data\"\n",
        "IMG_SIZE = 224 # for EffectiveNetB0\n",
        "\n",
        "def load_echo_data(data_list, data_dict):\n",
        "  for c in CATEGORIES:\n",
        "        path = path = DIRECTORY + \"/\" + c\n",
        "        class_name = CATEGORIES.index(c)\n",
        "        for img in os.listdir(path):\n",
        "            \n",
        "            try:\n",
        "                img_arr = cv2.imread(\n",
        "                    os.path.join(path, img),\n",
        "                    cv2.IMREAD_GRAYSCALE)\n",
        "                img_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "                data = [img_arr, class_name]\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "  random.shuffle(data_list)\n",
        "  \n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  verbose = 0\n",
        "  len_data = len(data_list)\n",
        "  for data in data_list:\n",
        "    images.append(tf.Variable([data[0]]))\n",
        "    labels.append(tf.Variable([data[1]]))\n",
        "\n",
        "  data_dict['images'] = tf.concat(images, axis = 0)\n",
        "  data_dict['labels'] = tf.concat(labels, axis = 0)\n",
        "\n",
        "  data_set = tf.data.Dataset.from_tensor_slices(data_dict)\n",
        "\n",
        "  return data_set\n",
        "\n"
      ],
      "metadata": {
        "id": "g5JfsH707Mrw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = load_echo_data(data_list, data_dict)"
      ],
      "metadata": {
        "id": "MH9Ar_vTCnnA"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}